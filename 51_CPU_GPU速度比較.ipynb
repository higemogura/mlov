{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CPUとGPUの速度比較"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Oct 11 05:29:07 2018       \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| NVIDIA-SMI 390.46                 Driver Version: 390.46                    |\r\n",
      "|-------------------------------+----------------------+----------------------+\r\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\r\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\r\n",
      "|===============================+======================+======================|\r\n",
      "|   0  Tesla K80           On   | 00009349:00:00.0 Off |                  Off |\r\n",
      "| N/A   54C    P0    57W / 149W |   7621MiB / 12206MiB |      0%      Default |\r\n",
      "+-------------------------------+----------------------+----------------------+\r\n",
      "                                                                               \r\n",
      "+-----------------------------------------------------------------------------+\r\n",
      "| Processes:                                                       GPU Memory |\r\n",
      "|  GPU       PID   Type   Process name                             Usage      |\r\n",
      "|=============================================================================|\r\n",
      "|    0     27040      C   /anaconda/envs/py35/bin/python              7609MiB |\r\n",
      "+-----------------------------------------------------------------------------+\r\n"
     ]
    }
   ],
   "source": [
    "# GPU確認 (例:Tesla K80,11441MiB)\n",
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Architecture:          x86_64\r\n",
      "CPU op-mode(s):        32-bit, 64-bit\r\n",
      "Byte Order:            Little Endian\r\n",
      "CPU(s):                6\r\n",
      "On-line CPU(s) list:   0-5\r\n",
      "Thread(s) per core:    1\r\n",
      "Core(s) per socket:    6\r\n",
      "Socket(s):             1\r\n",
      "NUMA node(s):          1\r\n",
      "Vendor ID:             GenuineIntel\r\n",
      "CPU family:            6\r\n",
      "Model:                 63\r\n",
      "Model name:            Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz\r\n",
      "Stepping:              2\r\n",
      "CPU MHz:               2596.994\r\n",
      "BogoMIPS:              5193.98\r\n",
      "Hypervisor vendor:     Microsoft\r\n",
      "Virtualization type:   full\r\n",
      "L1d cache:             32K\r\n",
      "L1i cache:             32K\r\n",
      "L2 cache:              256K\r\n",
      "L3 cache:              30720K\r\n",
      "NUMA node0 CPU(s):     0-5\r\n",
      "Flags:                 fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology cpuid pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm invpcid_single pti fsgsbase bmi1 avx2 smep bmi2 erms invpcid xsaveopt\r\n"
     ]
    }
   ],
   "source": [
    "# CPU確認 (例: CPU(s):6,Core(s) per socket:6,Model name:Intel(R) Xeon(R) CPU E5-2690 v3 @ 2.60GHz)\n",
    "!lscpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda/envs/py35/lib/python3.5/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "\n",
    "import chainer\n",
    "import chainer.links as L\n",
    "import chainer.functions as F\n",
    "from chainer import training\n",
    "from chainer.training import extensions\n",
    "from chainer.datasets import get_mnist\n",
    "train, test = get_mnist(ndim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(chainer.Chain):\n",
    "\n",
    "    def __init__(self, n_mid=100, n_out=10):\n",
    "        super().__init__()\n",
    "        with self.init_scope():\n",
    "            self.conv1 = L.Convolution2D(in_channels=1, out_channels=3, ksize=3, stride=1, pad=1)\n",
    "            self.fc1 = L.Linear(None, n_mid)\n",
    "            self.fc2 = L.Linear(None, n_out)\n",
    "\n",
    "    def __call__(self, x):\n",
    "        h = F.relu(self.conv1(x))\n",
    "        h = F.max_pooling_2d(h, 3, 3)\n",
    "        h = self.fc1(h)\n",
    "        h = self.fc2(h)\n",
    "        return h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "def reset_seed(seed=0):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    if chainer.cuda.available:\n",
    "        chainer.cuda.cupy.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<chainer.optimizers.adam.Adam at 0x7ff3a14c2748>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reset_seed(0)\n",
    "model = L.Classifier(CNN())\n",
    "\n",
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.setup(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "epoch = 10\n",
    "batchsize = 4096"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/accuracy  validation/main/accuracy  main/loss   validation/main/loss  elapsed_time\n",
      "\u001b[J1           0.908073       0.917768                  0.310181    0.276991              0.61195       \n",
      "\u001b[J2           0.911344       0.922069                  0.298212    0.266436              1.10112       \n",
      "\u001b[J3           0.913975       0.921907                  0.290048    0.2603                1.54908       \n",
      "\u001b[J4           0.915918       0.925356                  0.282858    0.253641              2.02476       \n",
      "\u001b[J5           0.918327       0.927163                  0.276306    0.248119              2.50212       \n",
      "\u001b[J6           0.91966        0.928058                  0.272294    0.24308               2.95065       \n",
      "\u001b[J7           0.921501       0.929528                  0.265435    0.238806              3.43077       \n",
      "\u001b[J8           0.921989       0.931118                  0.262856    0.233969              3.90934       \n",
      "\u001b[J9           0.923584       0.932425                  0.255301    0.230872              4.35748       \n",
      "\u001b[J10          0.924967       0.933277                  0.25297     0.229691              4.83516       \n",
      "CPU times: user 4.51 s, sys: 336 ms, total: 4.84 s\n",
      "Wall time: 4.84 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# CPUで実行 (gpu_id =0)\n",
    "gpu_id = 0\n",
    "\n",
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=gpu_id)\n",
    "trainer = training.Trainer(updater, (epoch, 'epoch'), out='chainer_log/cpu_gpu/')\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=gpu_id))\n",
    "trainer.extend(extensions.LogReport(trigger=(1, 'epoch')))\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/accuracy', 'validation/main/accuracy', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=(1, 'epoch'))\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch       main/accuracy  validation/main/accuracy  main/loss   validation/main/loss  elapsed_time\n",
      "\u001b[J1           0.435368       0.734087                  1.81212     1.21593               13.7002       \n",
      "\u001b[J2           0.764225       0.825155                  0.982017    0.710497              27.2574       \n",
      "\u001b[J3           0.828945       0.865682                  0.650916    0.519692              39.9986       \n",
      "\u001b[J4           0.863395       0.887997                  0.506171    0.424333              53.5172       \n",
      "\u001b[J5           0.878337       0.900983                  0.432325    0.372082              66.9656       \n",
      "\u001b[J6           0.888114       0.906815                  0.388988    0.341479              79.6434       \n",
      "\u001b[J7           0.894775       0.912148                  0.360426    0.318067              93.2092       \n",
      "\u001b[J8           0.901497       0.915028                  0.337094    0.301773              106.835       \n",
      "\u001b[J9           0.905814       0.919161                  0.321374    0.286662              119.584       \n",
      "\u001b[J10          0.909017       0.920957                  0.308698    0.275234              133.196       \n",
      "CPU times: user 2min 2s, sys: 1min 32s, total: 3min 34s\n",
      "Wall time: 2min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# CPUで実行 (gpu_id =-1)\n",
    "gpu_id =-1\n",
    "\n",
    "reset_seed(0)\n",
    "model = L.Classifier(CNN())\n",
    "\n",
    "optimizer = chainer.optimizers.Adam()\n",
    "optimizer.setup(model)\n",
    "\n",
    "train_iter = chainer.iterators.SerialIterator(train, batchsize)\n",
    "test_iter = chainer.iterators.SerialIterator(test, batchsize, repeat=False, shuffle=False)\n",
    "\n",
    "updater = training.StandardUpdater(train_iter, optimizer, device=gpu_id)\n",
    "\n",
    "trainer = training.Trainer(updater, (epoch, 'epoch'), out='chainer_log/cpu_gpu/')\n",
    "trainer.extend(extensions.Evaluator(test_iter, model, device=gpu_id))\n",
    "trainer.extend(extensions.LogReport(trigger=(1, 'epoch')))\n",
    "trainer.extend(extensions.PrintReport(['epoch', 'main/accuracy', 'validation/main/accuracy', 'main/loss', 'validation/main/loss', 'elapsed_time']), trigger=(1, 'epoch'))\n",
    "\n",
    "trainer.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py35]",
   "language": "python",
   "name": "conda-env-py35-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
