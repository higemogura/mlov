{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# word2vecによる単語のベクトル化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [銀河鉄道の夜]-宮沢賢治\n",
    "# https://www.aozora.gr.jp/cards/000081/files/456_15050.html\n",
    "# データの読込みと文字列の整形\n",
    "\n",
    "import codecs\n",
    "file = codecs.open('gingatetsudono_yoru.txt', \"r\", \"sjis\")\n",
    "text = file.read()\n",
    "file.close()\n",
    "\n",
    "import re\n",
    "text = re.split('\\-{5,}',text)[2]\n",
    "text = re.split('底本：',text)[0]\n",
    "text = text.replace('|', '')\n",
    "text = re.sub('《.+?》', '', text)\n",
    "text = re.sub('［＃.+?］', '',text)\n",
    "text = re.sub('\\n\\n', '\\n', text) \n",
    "text = re.sub('\\r', '', text)\n",
    "\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 参考: 形態素解析の実行\n",
    "from janome.tokenizer import Tokenizer\n",
    "t = Tokenizer()\n",
    "for token in t.tokenize(text[:50]):\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# word2vecを使用するための準備。不要な品詞を取り除く\n",
    "def extract_words(text):\n",
    "    tokens = t.tokenize(text)\n",
    "    return [token.base_form for token in tokens \n",
    "        if token.part_of_speech.split(',')[0] in['名詞', '動詞', '形容詞', '形容詞']]\n",
    "\n",
    "sentences = text.split('。')\n",
    "word_list = [extract_words(sentence) for sentence in sentences]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vecによる100次元の単語ベクトル生成\n",
    "from gensim.models import word2vec\n",
    "model = word2vec.Word2Vec(word_list, size=200,  window=5,iter=200)\n",
    "\n",
    "# 参考: 単語ベクトルの表示\n",
    "print(model.__dict__['wv']['ジョバンニ'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 単語の類似度を表示\n",
    "res = model.wv.most_similar(\n",
    "    positive=['ジョバンニ']) \n",
    "\n",
    "for item in res:\n",
    "    print(item[0], item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトルの計算 (ジョバンニ + こらえる)\n",
    "res = model.wv.most_similar(\n",
    "    positive=['ジョバンニ','こらえる']) \n",
    "\n",
    "for item in res:\n",
    "    print(item[0], item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ベクトルの計算 (ジョバンニ - 笑う)\n",
    "res = model.wv.most_similar(\n",
    "    positive=['ジョバンニ'],\n",
    "    negative=['笑う']) \n",
    "\n",
    "for item in res:\n",
    "    print(item[0], item[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
